{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Type hints\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "\n",
    "# Standard library\n",
    "import ast\n",
    "import logging\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "# Third-party packages - Data manipulation\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Third-party packages - Environment & Database\n",
    "from dotenv import load_dotenv\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Third-party packages - Error handling & Retry logic\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# Langchain - Core\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Langchain - Models & Connectors\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAI\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "# Langchain - Graph & Experimental\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "#from langchain_community.graphs import Neo4jGraph\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# api_key = os.getenv(\"GOOGLE_API_KEY\") # if you are using Google API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1901</td>\n",
       "      <td>Kansas Saloon Smashers</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...</td>\n",
       "      <td>A bartender is working at a saloon, serving dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1901</td>\n",
       "      <td>Love by the Light of the Moon</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Love_by_the_Ligh...</td>\n",
       "      <td>The moon, painted with a smiling face hangs ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1901</td>\n",
       "      <td>The Martyred Presidents</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/The_Martyred_Pre...</td>\n",
       "      <td>The film, just over a minute long, is composed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1901</td>\n",
       "      <td>Terrible Teddy, the Grizzly King</td>\n",
       "      <td>American</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Terrible_Teddy,_...</td>\n",
       "      <td>Lasting just 61 seconds and consisting of two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1902</td>\n",
       "      <td>Jack and the Beanstalk</td>\n",
       "      <td>American</td>\n",
       "      <td>George S. Fleming, Edwin S. Porter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Jack_and_the_Bea...</td>\n",
       "      <td>The earliest known adaptation of the classic f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Release Year                             Title Origin/Ethnicity  \\\n",
       "0          1901            Kansas Saloon Smashers         American   \n",
       "1          1901     Love by the Light of the Moon         American   \n",
       "2          1901           The Martyred Presidents         American   \n",
       "3          1901  Terrible Teddy, the Grizzly King         American   \n",
       "4          1902            Jack and the Beanstalk         American   \n",
       "\n",
       "                             Director Cast    Genre  \\\n",
       "0                             Unknown  NaN  unknown   \n",
       "1                             Unknown  NaN  unknown   \n",
       "2                             Unknown  NaN  unknown   \n",
       "3                             Unknown  NaN  unknown   \n",
       "4  George S. Fleming, Edwin S. Porter  NaN  unknown   \n",
       "\n",
       "                                           Wiki Page  \\\n",
       "0  https://en.wikipedia.org/wiki/Kansas_Saloon_Sm...   \n",
       "1  https://en.wikipedia.org/wiki/Love_by_the_Ligh...   \n",
       "2  https://en.wikipedia.org/wiki/The_Martyred_Pre...   \n",
       "3  https://en.wikipedia.org/wiki/Terrible_Teddy,_...   \n",
       "4  https://en.wikipedia.org/wiki/Jack_and_the_Bea...   \n",
       "\n",
       "                                                Plot  \n",
       "0  A bartender is working at a saloon, serving dr...  \n",
       "1  The moon, painted with a smiling face hangs ov...  \n",
       "2  The film, just over a minute long, is composed...  \n",
       "3  Lasting just 61 seconds and consisting of two ...  \n",
       "4  The earliest known adaptation of the classic f...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('data/wiki_movie_plots_deduped.csv')\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1907</td>\n",
       "      <td>Daniel boone</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace mccutcheon and ediwin s. porter</td>\n",
       "      <td>William craven, florence lawrence</td>\n",
       "      <td>Biographical</td>\n",
       "      <td>Boone's daughter befriends an indian maiden as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1908</td>\n",
       "      <td>The adventures of dollie</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Arthur v. johnson, linda arvidson</td>\n",
       "      <td>Drama</td>\n",
       "      <td>On a beautiful summer day a father and mother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1908</td>\n",
       "      <td>The black viper</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Drama</td>\n",
       "      <td>A thug accosts a girl as she leaves her workpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1908</td>\n",
       "      <td>A calamitous elopement</td>\n",
       "      <td>American</td>\n",
       "      <td>D.w. griffith</td>\n",
       "      <td>Harry solter, linda arvidson</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>A young couple decides to elope after being ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1908</td>\n",
       "      <td>The fight for freedom</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Florence auer, john g. adolfi</td>\n",
       "      <td>Western</td>\n",
       "      <td>The film opens in a town on the mexican border...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Year                     Title Origin/Ethnicity  \\\n",
       "13          1907              Daniel boone         American   \n",
       "16          1908  The adventures of dollie         American   \n",
       "17          1908           The black viper         American   \n",
       "18          1908    A calamitous elopement         American   \n",
       "21          1908     The fight for freedom         American   \n",
       "\n",
       "                                   Director  \\\n",
       "13  Wallace mccutcheon and ediwin s. porter   \n",
       "16                           D. w. griffith   \n",
       "17                           D. w. griffith   \n",
       "18                            D.w. griffith   \n",
       "21                           D. w. griffith   \n",
       "\n",
       "                                 Cast         Genre  \\\n",
       "13  William craven, florence lawrence  Biographical   \n",
       "16  Arthur v. johnson, linda arvidson         Drama   \n",
       "17                     D. w. griffith         Drama   \n",
       "18       Harry solter, linda arvidson        Comedy   \n",
       "21      Florence auer, john g. adolfi       Western   \n",
       "\n",
       "                                                 Plot  \n",
       "13  Boone's daughter befriends an indian maiden as...  \n",
       "16  On a beautiful summer day a father and mother ...  \n",
       "17  A thug accosts a girl as she leaves her workpl...  \n",
       "18  A young couple decides to elope after being ca...  \n",
       "21  The film opens in a town on the mexican border...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean and preprocess DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data: Input DataFrame\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    df.drop([\"Wiki Page\"], axis=1, inplace=True)\n",
    "\n",
    "    # Find duplicate rows based on 'Title' column\n",
    "    duplicates = df[df.duplicated(subset='Title', keep=False)]\n",
    "\n",
    "    # Drop duplicate rows from original DataFrame\n",
    "    df = df[~df['Title'].isin(duplicates['Title'])]\n",
    "\n",
    "    # Clean string columns by stripping whitespace and replacing unknown/empty values\n",
    "    # Get object columns\n",
    "    col_obj = df.select_dtypes(include=[\"object\"]).columns\n",
    "    \n",
    "    # Clean string columns\n",
    "    for col in col_obj:\n",
    "        # Strip whitespace\n",
    "        df[col] = df[col].str.strip()\n",
    "        \n",
    "        # Replace unknown/empty values\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: None if pd.isna(x) or x.lower() in [\"\", \"unknown\"] \n",
    "            else x.capitalize()\n",
    "        )\n",
    "    \n",
    "    # Drop rows with any null values\n",
    "    df = df.dropna(how=\"any\", axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "movies = clean_data(movies).head(1000)\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection verified successfully!\n",
      "CREATE (n:name:description {name: 'Document1', description: 'First document'})\n",
      "CREATE (n:name:description {name: 'Document2', description: 'Second document'})\n",
      "[<Record n=<Node element_id='4:3ca04924-064a-4d29-a844-6f7f08426147:0' labels=frozenset({'name', 'description'}) properties={'name': 'Document1', 'description': 'First document'}>>, <Record n=<Node element_id='4:3ca04924-064a-4d29-a844-6f7f08426147:1' labels=frozenset({'name', 'description'}) properties={'name': 'Document2', 'description': 'Second document'}>>]\n",
      "Database resetted successfully!\n"
     ]
    }
   ],
   "source": [
    "#Connect to neo and reset the database\n",
    "\n",
    "import neo4j \n",
    "\n",
    "class Neo4jConnection:\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "    \n",
    "    def close(self):\n",
    "        if hasattr(self, 'driver') and self.driver:\n",
    "            self.driver.close()\n",
    "            print(\"Connection closed\")\n",
    "    \n",
    "    def reset_database(self):\n",
    "        with self.driver.session() as session:\n",
    "            session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        print(\"Database resetted successfully!\")\n",
    "    \n",
    "    def add_document(self, documents: list):\n",
    "        with self.driver.session() as session:\n",
    "            for doc in documents:\n",
    "                # Generate the labels string\n",
    "                labels = \":\".join([key for key in doc.keys()])  # Use multiple labels if needed\n",
    "\n",
    "                # Generate properties string for Cypher query\n",
    "                props_string = \", \".join(\n",
    "                    f\"{key}: '{value}'\" if isinstance(value, str) else f\"{key}: {value}\"\n",
    "                    for key, value in doc.items()\n",
    "                )\n",
    "\n",
    "                # Construct the Cypher CREATE query\n",
    "                query = f\"CREATE (n:{labels} {{{props_string}}})\"\n",
    "                print(query)  # For debugging purposes\n",
    "\n",
    "                # Execute the query\n",
    "                session.run(query)\n",
    "   \n",
    "    def execute_query(self, query, parameters=None):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return [record for record in result]\n",
    "    \n",
    "    def verify_connection(self):\n",
    "        try:\n",
    "            # Try to run a simple query\n",
    "            with self.driver.session() as session:\n",
    "                session.run(\"RETURN 1\")\n",
    "            print(\"Connection verified successfully!\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Connection verification failed: {e}\")\n",
    "            if isinstance(e, neo4j.exceptions.AuthError):\n",
    "                print(\"Authentication error. Please check your username and password.\")\n",
    "            elif isinstance(e, neo4j.exceptions.ServiceUnavailable):\n",
    "                print(\"Could not connect to the Neo4j server. Check the server status and network configuration.\")\n",
    "            return False\n",
    "\n",
    "# Connect to Neo4j\n",
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"cinema123\"\n",
    "\n",
    "conn = Neo4jConnection(uri, user, password)\n",
    "\n",
    "# Verify the connection before proceeding with any other operations\n",
    "if conn.verify_connection():\n",
    "    # Proceed with your operations here\n",
    "    conn.add_document([{\"name\": \"Document1\", \"description\": \"First document\"}, {\"name\": \"Document2\", \"description\": \"Second document\"}])\n",
    "    result = conn.execute_query(\"MATCH (n) RETURN n\")\n",
    "    print(result)\n",
    "    conn.reset_database()\n",
    "else:\n",
    "    print(\"Failed to establish connection. Exiting.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Moviews to Neo Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading movies: 100%|██████████| 1000/1000 [01:37<00:00, 10.23it/s]\n",
      "INFO:__main__:Finished loading movies to Neo4j\n"
     ]
    }
   ],
   "source": [
    "def parse_number(value: Any, target_type: type) -> Optional[float]:\n",
    "    \"\"\"Parse string to number with proper error handling.\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    try:\n",
    "        cleaned = str(value).strip().replace(',', '')\n",
    "        return target_type(cleaned)\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Clean and normalize text fields.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return str(text).strip().title()\n",
    "\n",
    "def load_movies_to_neo4j(movies_df: pd.DataFrame, connection: GraphDatabase) -> None:\n",
    "    \"\"\"Load movie data into Neo4j with progress tracking and error handling.\"\"\"\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    \n",
    "    # Query templates\n",
    "    MOVIE_QUERY = \"\"\"\n",
    "        MERGE (movie:Movie {title: $title})\n",
    "        SET movie.year = $year,\n",
    "            movie.origin = $origin,\n",
    "            movie.genre = $genre,\n",
    "            movie.plot = $plot\n",
    "    \"\"\"\n",
    "    \n",
    "    DIRECTOR_QUERY = \"\"\"\n",
    "        MATCH (movie:Movie {title: $title})\n",
    "        MERGE (director:Director {name: $name})\n",
    "        MERGE (director)-[:DIRECTED]->(movie)\n",
    "    \"\"\"\n",
    "    \n",
    "    ACTOR_QUERY = \"\"\"\n",
    "        MATCH (movie:Movie {title: $title})\n",
    "        MERGE (actor:Actor {name: $name})\n",
    "        MERGE (actor)-[:ACTED_IN]->(movie)\n",
    "    \"\"\"\n",
    "\n",
    "    # Process each movie\n",
    "    for _, row in tqdm(movies_df.iterrows(), total=len(movies_df), desc=\"Loading movies\"):\n",
    "        try:\n",
    "            # Prepare movie parameters\n",
    "            movie_params = {\n",
    "                \"title\": clean_text(row[\"Title\"]),\n",
    "                \"year\": parse_number(row[\"Release Year\"], int),\n",
    "                \"origin\": clean_text(row[\"Origin/Ethnicity\"]),\n",
    "                \"genre\": clean_text(row[\"Genre\"]),\n",
    "                \"plot\": str(row[\"Plot\"]).strip()\n",
    "            }\n",
    "            \n",
    "            # Create movie node\n",
    "            connection.execute_query(MOVIE_QUERY, parameters=movie_params)\n",
    "            \n",
    "            # Process directors\n",
    "            for director in str(row[\"Director\"]).split(\" and \"):\n",
    "                director_params = {\n",
    "                    \"name\": clean_text(director),\n",
    "                    \"title\": movie_params[\"title\"]\n",
    "                }\n",
    "                connection.execute_query(DIRECTOR_QUERY, parameters=director_params)\n",
    "            \n",
    "            # Process cast\n",
    "            if pd.notna(row[\"Cast\"]):\n",
    "                for actor in row[\"Cast\"].split(\",\"):\n",
    "                    actor_params = {\n",
    "                        \"name\": clean_text(actor),\n",
    "                        \"title\": movie_params[\"title\"]\n",
    "                    }\n",
    "                    connection.execute_query(ACTOR_QUERY, parameters=actor_params)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading {row['Title']}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    logger.info(\"Finished loading movies to Neo4j\")\n",
    "\n",
    "# Load DataFrame to Neo4j\n",
    "load_movies_to_neo4j(movies, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record m.title='Daniel Boone' a.name='William Craven'>,\n",
       " <Record m.title='Daniel Boone' a.name='Florence Lawrence'>,\n",
       " <Record m.title='The Adventures Of Dollie' a.name='Arthur V. Johnson'>,\n",
       " <Record m.title=\"A Drunkard'S Reformation\" a.name='Arthur V. Johnson'>,\n",
       " <Record m.title='The Adventures Of Dollie' a.name='Linda Arvidson'>,\n",
       " <Record m.title='A Calamitous Elopement' a.name='Linda Arvidson'>,\n",
       " <Record m.title='The Black Viper' a.name='D. W. Griffith'>,\n",
       " <Record m.title='A Calamitous Elopement' a.name='Harry Solter'>,\n",
       " <Record m.title='The Fight For Freedom' a.name='Florence Auer'>,\n",
       " <Record m.title='The Fight For Freedom' a.name='John G. Adolfi'>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH (m:Movie)-[:ACTED_IN]-(a:Actor)\n",
    "RETURN m.title, a.name\n",
    "LIMIT 10;\n",
    "\"\"\"\n",
    "conn.execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imgs/bloom-visualisation.png\" alt=\"Movies plotted using Neo Bloom\" style=\"width:1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database resetted successfully!\n"
     ]
    }
   ],
   "source": [
    "conn.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release Year: 1907, 1908, 1908...\n",
      "Title: Daniel boone, The adventures of dollie, The black viper...\n",
      "Origin/Ethnicity: American, American, American...\n",
      "Director: Wallace mccutcheon and ediwin s. porter, D. w. griffith, D. w. griffith...\n",
      "Cast: William craven, florence lawrence, Arthur v. johnson, linda arvidson, D. w. griffith...\n",
      "Genre: Biographical, Drama, Drama...\n",
      "Plot: Boone's daughter befriends an indian maiden as boone and his companion start out on a hunting expedition. while he is away, boone's cabin is attacked by the indians, who set it on fire and abduct boone's daughter. boone returns, swears vengeance, then heads out on the trail to the indian camp. his daughter escapes but is chased. the indians encounter boone, which sets off a huge fight on the edge of a cliff. a burning arrow gets shot into the indian camp. boone gets tied to the stake and tortured. the burning arrow sets the indian camp on fire, causing panic. boone is rescued by his horse, and boone has a knife fight in which he kills the indian chief.[2], On a beautiful summer day a father and mother take their daughter dollie on an outing to the river. the mother refuses to buy a gypsy's wares. the gypsy tries to rob the mother, but the father drives him off. the gypsy returns to the camp and devises a plan. they return and kidnap dollie while her parents are distracted. a rescue crew is organized, but the gypsy takes dollie to his camp. they gag dollie and hide her in a barrel before the rescue party gets to the camp. once they leave the gypsies and escapes in their wagon. as the wagon crosses the river, the barrel falls into the water. still sealed in the barrel, dollie is swept downstream in dangerous currents. a boy who is fishing in the river finds the barrel, and dollie is reunited safely with her parents., A thug accosts a girl as she leaves her workplace but a man rescues her. the thug vows revenge and, with the help of two friends, attacks the girl and her rescuer again as they're going for a walk. this time they succeed in kidnapping the rescuer. he is bound and gagged and taken away in a cart. the girl runs home and gets help from several neighbors. they track the ruffians down to a cabin in the mountains where the gang has trapped their victim and set the cabin on fire. a thug and rescuer fight on the roof of the house....\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM\n",
    "# llm = GoogleGenerativeAI(model=\"gemini-1.5-flash\", google_api_key=api_key) # if you are using Google API\n",
    "llm = OllamaLLM(model=\"qwen2.5-coder:latest\")\n",
    "\n",
    "df = movies.copy()\n",
    "\n",
    "# Step 1: Define Node Labels and Properties\n",
    "node_structure = \"\\n\".join(\n",
    "    [f\"{col}: {', '.join(map(str, df[col][:3]))}...\" for col in df.columns]\n",
    ")\n",
    "\n",
    "print(node_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Node Definitions: {'Movie': {'Release Year': 'row[\"Release Year\"]', 'Title': 'row[\"Title\"]'}, 'Director': {'Name': 'row[\"Director\"]'}, 'Cast': {'Name': 'row[\"Cast\"]'}, 'Genre': {'Type': 'row[\"Genre\"]'}, 'Plot': {'Description': 'row[\"Plot\"]'}, 'Origin/Ethnicity': {'Ethnicity': 'row[\"Origin/Ethnicity\"]'}}\n"
     ]
    }
   ],
   "source": [
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def validate_node_definition(node_def: Dict) -> bool:\n",
    "    \"\"\"Validates the structure of the node_def dictionary returned by the system (likely an AI model or a similar generator). The expected structure of node_def is:\n",
    "    {\n",
    "    \"NodeLabel1\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
    "    \"NodeLabel2\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2']\"},\n",
    "}\n",
    "This function ensures that the generated node definitions are correctly formatted before they are used elsewhere. It avoids potential downstream errors \n",
    "by performing an early validation.\n",
    "\"\"\"\n",
    "    if not isinstance(node_def, dict):\n",
    "        return False\n",
    "    return all(\n",
    "        isinstance(v, dict) and all(isinstance(k, str) for k in v.keys())\n",
    "        for v in node_def.values()\n",
    "    )\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def get_node_definitions(chain, structure: str, example: Dict) -> Dict[str, Dict[str, str]]:\n",
    "    \"\"\"Fetches and validates the node definitions using a chain (e.g., a Language Model processing pipeline), with retry logic in case of transient failures.\n",
    "    1. Invoke the chain: Uses the chain object to call an external process (likely an LLM) and pass the structure (dataset description) and an example (template) as inputs.\n",
    "    2. Parse response: Attempts to evaluate the returned string into a Python dictionary using ast.literal_eval(). This ensures that the returned structure is properly parsed without executing unsafe code.\n",
    "    3. Validate response: Calls validate_node_definition() to ensure the response is correctly formatted.\n",
    "    4. Retry on errors: Retries up to 3 times with exponential backoff if parsing or validation fails.\"\"\"\n",
    "    try:\n",
    "        # Get response from LLM\n",
    "        response = chain.invoke({\"structure\": structure, \"example\": example})\n",
    "        \n",
    "        # Parse response\n",
    "        node_defs = ast.literal_eval(response)\n",
    "        \n",
    "        # Validate structure\n",
    "        if not validate_node_definition(node_defs):\n",
    "            raise ValueError(\"Invalid node definition structure\")\n",
    "            \n",
    "        return node_defs\n",
    "        \n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        logger.error(f\"Error parsing node definitions: {e}\")\n",
    "        raise\n",
    "\n",
    "# Updated node definition template\n",
    "node_example = {\n",
    "    \"NodeLabel1\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2'], ...\"},\n",
    "    \"NodeLabel2\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2'], ...\"},\n",
    "    \"NodeLabel3\": {\"property1\": \"row['property1']\", \"property2\": \"row['property2'], ...\"},\n",
    "}\n",
    "\n",
    "define_nodes_prompt = PromptTemplate(\n",
    "    input_variables=[\"example\", \"structure\"],\n",
    "    template=(\"\"\"\n",
    "        Analyze the dataset structure below and extract the entity labels for nodes and their properties.\\n\n",
    "        The node properties should be based on the dataset columns and their values.\\n\n",
    "        Return the result as a dictionary where the keys are the node labels and the values are the node properties.\\n\\n\n",
    "        Example: {example}\\n\\n\n",
    "        \n",
    "        Dataset Structure:\\n{structure}\\n\\n\n",
    "              \n",
    "        Make sure to include all the possible node labels and their properties.\\n\n",
    "        If a property can be its own node, include it as a separate node label.\\n\n",
    "        Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\n",
    "        Return only the dictionary containing node labels and properties, and don't include any other text or quotation.\n",
    "        \n",
    "        \"\"\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Execute with error handling\n",
    "try:\n",
    "    node_chain = define_nodes_prompt | llm\n",
    "\n",
    "    node_definitions = get_node_definitions(node_chain, structure=node_structure, example=node_example)\n",
    "    logger.info(f\"Node Definitions: {node_definitions}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to get node definitions: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Identified 5 relationships\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationships: [('Movie', 'Directed by', 'Director'), ('Movie', 'Starring', 'Cast'), ('Movie', 'Genre', 'Genre'), ('Movie', 'Plot Description', 'Plot'), ('Movie', 'Origin/Ethnicity', 'Origin/Ethnicity')]\n"
     ]
    }
   ],
   "source": [
    "class RelationshipIdentifier:\n",
    "    \"\"\"\n",
    "    Identifies relationships (edges) between nodes in a graph database.\n",
    "\n",
    "    This class uses a language model (LLM) to analyze a dataset's structure and \n",
    "    node definitions, and it identifies relationships based on those inputs. \n",
    "    It provides validation for the relationships and implements retry logic to \n",
    "    ensure robustness in handling failures.\n",
    "    \"\"\"\n",
    "\n",
    "    RELATIONSHIP_EXAMPLE = [\n",
    "        (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel2\"),\n",
    "        (\"NodeLabel1\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
    "        (\"NodeLabel2\", \"RelationshipLabel\", \"NodeLabel3\"),\n",
    "    ]\n",
    "    \"\"\"\n",
    "    Example relationships:\n",
    "    - Each tuple represents a relationship with:\n",
    "        1. Start node label (e.g., \"NodeLabel1\")\n",
    "        2. Relationship label (e.g., \"RelationshipLabel\")\n",
    "        3. End node label (e.g., \"NodeLabel2\")\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT_TEMPLATE = PromptTemplate(\n",
    "        input_variables=[\"structure\", \"node_definitions\", \"example\"],\n",
    "        template=\"\"\"\n",
    "            Consider the following Dataset Structure:\\n{structure}\\n\\n\n",
    "\n",
    "            Consider the following Node Definitions:\\n{node_definitions}\\n\\n\n",
    "\n",
    "            Based on the dataset structure and node definitions, identify relationships (edges) between nodes.\\n\n",
    "            Return the relationships as a list of triples where each triple contains the start node label, relationship label, and end node label, and each triple is a tuple.\\n\n",
    "            Please return only the list of tuples. Please do not report triple backticks to identify a code block, just return the list of tuples.\\n\\n\n",
    "\n",
    "            Example:\\n{example}\n",
    "        \"\"\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    Prompt template for relationship extraction:\n",
    "    - Guides the LLM to extract relationships between nodes.\n",
    "    - Uses the dataset structure, node definitions, and examples as inputs.\n",
    "    - Ensures the output is formatted as a list of tuples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm: Any, logger: logging.Logger = None):\n",
    "        \"\"\"\n",
    "        Initializes the RelationshipIdentifier.\n",
    "\n",
    "        Args:\n",
    "            llm (Any): The language model used for processing prompts.\n",
    "            logger (logging.Logger, optional): Logger instance for logging activities. \n",
    "                Defaults to a module-level logger.\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.chain = self.PROMPT_TEMPLATE | self.llm\n",
    "\n",
    "    def validate_relationships(self, relationships: List[Tuple]) -> bool:\n",
    "        \"\"\"\n",
    "        Validate the structure of identified relationships.\n",
    "\n",
    "        Ensures that:\n",
    "        - Each relationship is a tuple of length 3.\n",
    "        - All elements of each tuple are strings.\n",
    "\n",
    "        Args:\n",
    "            relationships (List[Tuple]): The list of relationships to validate.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if all relationships are valid, False otherwise.\n",
    "        \"\"\"\n",
    "        return all(\n",
    "            isinstance(rel, tuple) and \n",
    "            len(rel) == 3 and \n",
    "            all(isinstance(x, str) for x in rel)\n",
    "            for rel in relationships\n",
    "        )\n",
    "\n",
    "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "    def identify_relationships(self, structure: str, node_definitions: Dict) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Identify relationships between nodes based on dataset structure and node definitions.\n",
    "\n",
    "        Implements retry logic to handle transient errors during interaction with the LLM.\n",
    "\n",
    "        Args:\n",
    "            structure (str): The dataset structure to analyze.\n",
    "            node_definitions (Dict): The node definitions as a dictionary.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple]: A list of identified relationships as tuples.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If the relationships cannot be identified or validated.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.chain.invoke({\n",
    "                \"structure\": structure, \n",
    "                \"node_definitions\": str(node_definitions), \n",
    "                \"example\": str(self.RELATIONSHIP_EXAMPLE)\n",
    "            })\n",
    "            \n",
    "            # Parse the LLM response into a Python object\n",
    "            relationships = ast.literal_eval(response)\n",
    "            \n",
    "            # Validate the structure of the relationships\n",
    "            if not self.validate_relationships(relationships):\n",
    "                raise ValueError(\"Invalid relationship structure\")\n",
    "                \n",
    "            self.logger.info(f\"Identified {len(relationships)} relationships\")\n",
    "            return relationships\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error identifying relationships: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_relationship_types(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Extract unique relationship types from identified relationships.\n",
    "\n",
    "        This method relies on the `identify_relationships` method to fetch relationships\n",
    "        and then extracts the unique relationship labels (second element of each tuple).\n",
    "\n",
    "        Returns:\n",
    "            List[str]: A list of unique relationship types.\n",
    "        \"\"\"\n",
    "        return list(set(rel[1] for rel in self.identify_relationships()))\n",
    "\n",
    "# Usage Example\n",
    "# Initialize the identifier with a language model instance (llm)\n",
    "identifier = RelationshipIdentifier(llm=llm)\n",
    "\n",
    "# Identify relationships using dataset structure and node definitions\n",
    "relationships = identifier.identify_relationships(node_structure, node_definitions)\n",
    "\n",
    "# Output the identified relationships\n",
    "print(\"Relationships:\", relationships)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Successfully generated Cypher queries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cypher Queries: cypher CREATE (m:Movie {Release_Year: row[\"Release Year\"], Title: row[\"Title\"]}); CREATE (d:Director {Name: row[\"Director\"]}); CREATE (c:Cast {Name: row[\"Cast\"]}); CREATE (g:Genre {Type: row[\"Genre\"]}); CREATE (p:Plot {Description: row[\"Plot\"]}); CREATE (oe:Origin_Ethnicity {Ethnicity: row[\"Origin/Ethnicity\"]}); CREATE (m)-[:Directed_by]->(d); CREATE (m)-[:Starring]->(c); CREATE (m)-[:Genre]->(g); CREATE (m)-[:Plot_Description]->(p); CREATE (m)-[:Origin_Ethnicity]->(oe);\n"
     ]
    }
   ],
   "source": [
    "class CypherQueryBuilder:\n",
    "    \"\"\"Builds Cypher queries for Neo4j graph database.\"\"\"\n",
    "\n",
    "    INPUT_EXAMPLE = \"\"\"\n",
    "    NodeLabel1: value1, value2\n",
    "    NodeLabel2: value1, value2\n",
    "    \"\"\"\n",
    "\n",
    "    EXAMPLE_CYPHER = \"\"\"\n",
    "    CREATE (n1:NodeLabel1 {property1: row['property1'], property2: row['property2']})\n",
    "    CREATE (n2:NodeLabel2 {property1: row['property1'], property2: row['property2']})\n",
    "    CREATE (n1)-[:RelationshipLabel]->(n2);\n",
    "    \"\"\"\n",
    "\n",
    "    PROMPT_TEMPLATE = PromptTemplate(\n",
    "        input_variables=[\"node_definitions\", \"relationships\", \"input\", \"cypher\"],\n",
    "        template=\"\"\"\n",
    "        Node Definitions:\\n{node_definitions}\\n\\n\n",
    "        Relationships:\\n{relationships}\\n\\n\n",
    "        Generate Cypher queries to create nodes and relationships using the node definitions and relationships provided.\\n\n",
    "        Replace placeholder values with dataset properties. Return Cypher queries as a single string with each query separated by a semicolon (;).\\n\n",
    "        Example Input:\\n{input}\\n\\n\n",
    "        Example Cypher Query:\\n{cypher}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    def __init__(self, llm: Any, logger: logging.Logger = None):\n",
    "        self.llm = llm\n",
    "        self.logger = logger or logging.getLogger(__name__)\n",
    "        self.chain = self.PROMPT_TEMPLATE | self.llm\n",
    "\n",
    "    def validate_cypher_query(self, query: str) -> bool:\n",
    "        \"\"\"Validate Cypher query syntax using regex patterns.\"\"\"\n",
    "        try:\n",
    "            patterns = [\n",
    "                r'CREATE \\([\\w:]+ \\{.*?\\}\\)',  # Node creation with properties\n",
    "                r'\\)-\\[:[\\w:]+\\]->\\(',        # Relationship syntax\n",
    "                r'\\{.*?\\}'                   # Valid property dictionary\n",
    "            ]\n",
    "            if not all(re.search(pattern, query) for pattern in patterns):\n",
    "                self.logger.warning(f\"Regex validation failed for query: {query}\")\n",
    "                return False\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "    def sanitize_query(self, query: str) -> str:\n",
    "        \"\"\"Sanitize and format Cypher query.\"\"\"\n",
    "        return query.strip().replace('\\n', ' ').replace('  ', ' ')\n",
    "\n",
    "    def sanitize_node_definitions(self, node_definitions: Dict) -> Dict:\n",
    "        \"\"\"Sanitize node definitions to ensure valid Cypher syntax.\"\"\"\n",
    "        sanitized = {}\n",
    "        for label, properties in node_definitions.items():\n",
    "            sanitized_label = label.replace(' ', '_').replace('/', '_')\n",
    "            sanitized_properties = {\n",
    "                k.replace(' ', '_').replace('/', '_'): v for k, v in properties.items()\n",
    "            }\n",
    "            sanitized[sanitized_label] = sanitized_properties\n",
    "        return sanitized\n",
    "\n",
    "    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "    def build_queries(self, node_definitions: Dict, relationships: List) -> str:\n",
    "        \"\"\"Build Cypher queries with retry logic.\"\"\"\n",
    "        try:\n",
    "            response = self.chain.invoke({\n",
    "                \"node_definitions\": str(self.sanitize_node_definitions(node_definitions)),\n",
    "                \"relationships\": str(relationships),\n",
    "                \"input\": self.INPUT_EXAMPLE,\n",
    "                \"cypher\": self.EXAMPLE_CYPHER\n",
    "            })\n",
    "\n",
    "            # Extract response if wrapped in triple backticks\n",
    "            response = response.strip('`') if response.startswith('```') else response\n",
    "\n",
    "            # Sanitize response\n",
    "            queries = self.sanitize_query(response)\n",
    "            self.logger.debug(f\"Sanitized query: {queries}\")\n",
    "\n",
    "            # Validate queries\n",
    "            if not self.validate_cypher_query(queries):\n",
    "                raise ValueError(\"Invalid Cypher query syntax\")\n",
    "\n",
    "            self.logger.info(\"Successfully generated Cypher queries\")\n",
    "            return queries\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error building Cypher queries: {e}\")\n",
    "            raise\n",
    "\n",
    "    def split_queries(self, queries: str) -> List[str]:\n",
    "        \"\"\"Split combined Cypher queries into individual statements.\"\"\"\n",
    "        return [q.strip() for q in queries.split(';') if q.strip()]\n",
    "\n",
    "\n",
    "# Usage Example\n",
    "# Assuming `llm` is a valid LLM instance and `node_definitions` and `relationships` are defined\n",
    "builder = CypherQueryBuilder(llm=llm)\n",
    "cypher_queries = builder.build_queries(node_definitions, relationships)\n",
    "print(\"Cypher Queries:\", cypher_queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data to Neo4j: 100%|██████████| 1000/1000 [04:17<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over dataframe with progress bar\n",
    "logs = \"\"\n",
    "total_rows = len(df)\n",
    "\n",
    "def sanitize_value(value):\n",
    "    \"\"\"Sanitize and return value for Cypher query.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        return value.replace('\"', '\\\\\"')  # Escape double quotes\n",
    "    return str(value)\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), \n",
    "                      total=total_rows,\n",
    "                      desc=\"Loading data to Neo4j\",\n",
    "                      position=0,\n",
    "                      leave=True):\n",
    "    try:\n",
    "        # Generate individual CREATE statements\n",
    "        queries = [\n",
    "            f'CREATE (m:Movie {{Release_Year: \"{sanitize_value(row[\"Release Year\"])}\", Title: \"{sanitize_value(row[\"Title\"])}\"}});',\n",
    "            f'CREATE (d:Director {{Name: \"{sanitize_value(row[\"Director\"])}\"}});',\n",
    "            f'CREATE (c:Cast {{Name: \"{sanitize_value(row[\"Cast\"])}\"}});',\n",
    "            f'CREATE (g:Genre {{Type: \"{sanitize_value(row[\"Genre\"])}\"}});',\n",
    "            f'CREATE (p:Plot {{Description: \"{sanitize_value(row[\"Plot\"])}\"}});',\n",
    "            f'CREATE (oe:Origin_Ethnicity {{Ethnicity: \"{sanitize_value(row[\"Origin/Ethnicity\"])}\"}});',\n",
    "            f'CREATE (m)-[:Directed_by]->(d);',\n",
    "            f'CREATE (m)-[:Starring]->(c);',\n",
    "            f'CREATE (m)-[:Genre]->(g);',\n",
    "            f'CREATE (m)-[:Plot_Description]->(p);',\n",
    "            f'CREATE (m)-[:Origin_Ethnicity]->(oe);'\n",
    "        ]\n",
    "\n",
    "        # Execute each query separately\n",
    "        for query in queries:\n",
    "            conn.execute_query(query)\n",
    "            \n",
    "    except Exception as e:\n",
    "        logs += f\"Error on row {index+1}: {str(e)}\\n\"\n",
    "\n",
    "# Display logs\n",
    "print(logs)  # Uncomment to display logs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "MATCH p=(m:Movie)-[r]-(n)\n",
    "RETURN p\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "conn.execute_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![custom_graph_builder.jpeg](imgs/custom_graph_builder.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database resetted successfully!\n"
     ]
    }
   ],
   "source": [
    "conn.reset_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1907</td>\n",
       "      <td>Daniel boone</td>\n",
       "      <td>American</td>\n",
       "      <td>Wallace mccutcheon and ediwin s. porter</td>\n",
       "      <td>William craven, florence lawrence</td>\n",
       "      <td>Biographical</td>\n",
       "      <td>Boone's daughter befriends an indian maiden as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1908</td>\n",
       "      <td>The adventures of dollie</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Arthur v. johnson, linda arvidson</td>\n",
       "      <td>Drama</td>\n",
       "      <td>On a beautiful summer day a father and mother ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1908</td>\n",
       "      <td>The black viper</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Drama</td>\n",
       "      <td>A thug accosts a girl as she leaves her workpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1908</td>\n",
       "      <td>A calamitous elopement</td>\n",
       "      <td>American</td>\n",
       "      <td>D.w. griffith</td>\n",
       "      <td>Harry solter, linda arvidson</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>A young couple decides to elope after being ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1908</td>\n",
       "      <td>The fight for freedom</td>\n",
       "      <td>American</td>\n",
       "      <td>D. w. griffith</td>\n",
       "      <td>Florence auer, john g. adolfi</td>\n",
       "      <td>Western</td>\n",
       "      <td>The film opens in a town on the mexican border...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Release Year                     Title Origin/Ethnicity  \\\n",
       "13          1907              Daniel boone         American   \n",
       "16          1908  The adventures of dollie         American   \n",
       "17          1908           The black viper         American   \n",
       "18          1908    A calamitous elopement         American   \n",
       "21          1908     The fight for freedom         American   \n",
       "\n",
       "                                   Director  \\\n",
       "13  Wallace mccutcheon and ediwin s. porter   \n",
       "16                           D. w. griffith   \n",
       "17                           D. w. griffith   \n",
       "18                            D.w. griffith   \n",
       "21                           D. w. griffith   \n",
       "\n",
       "                                 Cast         Genre  \\\n",
       "13  William craven, florence lawrence  Biographical   \n",
       "16  Arthur v. johnson, linda arvidson         Drama   \n",
       "17                     D. w. griffith         Drama   \n",
       "18       Harry solter, linda arvidson        Comedy   \n",
       "21      Florence auer, john g. adolfi       Western   \n",
       "\n",
       "                                                 Plot  \n",
       "13  Boone's daughter befriends an indian maiden as...  \n",
       "16  On a beautiful summer day a father and mother ...  \n",
       "17  A thug accosts a girl as she leaves her workpl...  \n",
       "18  A young couple decides to elope after being ca...  \n",
       "21  The film opens in a town on the mexican border...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtext\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating documents: 100%|██████████| 100/100 [00:00<00:00, 17015.43it/s]\n"
     ]
    }
   ],
   "source": [
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "df_sample = df.head(100) # Reduce sample size for faster processing\n",
    "\n",
    "documents = []\n",
    "for _, row in tqdm(df_sample.iterrows(), \n",
    "                   total=len(df_sample), \n",
    "                   desc=\"Creating documents\",\n",
    "                   position=0, \n",
    "                   leave=True):\n",
    "    try:\n",
    "        # Format text with proper line breaks\n",
    "        text = \"\"\n",
    "\n",
    "        for col in df.columns:\n",
    "            text += f\"{col}: {row[col]}\\n\"\n",
    "        \n",
    "        documents.append(Document(page_content=text))\n",
    "        \n",
    "    except KeyError as e:\n",
    "        tqdm.write(f\"Missing column: {e}\")\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error processing row: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "POST predict: Post \"http://127.0.0.1:54730/completion\": read tcp 127.0.0.1:54734->127.0.0.1:54730: wsarecv: An existing connection was forcibly closed by the remote host.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[96], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m graph_documents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m llm_transformer\u001b[38;5;241m.\u001b[39maconvert_to_graph_documents(documents)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNodes:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_documents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRelationships:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgraph_documents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrelationships\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_experimental\\graph_transformers\\llm.py:1022\u001b[0m, in \u001b[0;36mLLMGraphTransformer.aconvert_to_graph_documents\u001b[1;34m(self, documents, config)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;124;03mAsynchronously convert a sequence of documents into graph documents.\u001b[39;00m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1018\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1019\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mcreate_task(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maprocess_response(document, config))\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents\n\u001b[0;32m   1021\u001b[0m ]\n\u001b[1;32m-> 1022\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_experimental\\graph_transformers\\llm.py:933\u001b[0m, in \u001b[0;36mLLMGraphTransformer.aprocess_response\u001b[1;34m(self, document, config)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03mAsynchronously processes a single document, transforming it into a\u001b[39;00m\n\u001b[0;32m    930\u001b[0m \u001b[38;5;124;03mgraph document.\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    932\u001b[0m text \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mpage_content\n\u001b[1;32m--> 933\u001b[0m raw_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mainvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: text}, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_call:\n\u001b[0;32m    935\u001b[0m     raw_schema \u001b[38;5;241m=\u001b[39m cast(Dict[Any, Any], raw_schema)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3066\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m     part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asyncio_accepts_context():\n\u001b[1;32m-> 3066\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part(), context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3068\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part())\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:413\u001b[0m, in \u001b[0;36mBaseLLM.ainvoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    411\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    412\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m--> 413\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[0;32m    414\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    415\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    416\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    417\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    418\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    419\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    420\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    421\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    422\u001b[0m     )\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:765\u001b[0m, in \u001b[0;36mBaseLLM.agenerate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    759\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    763\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    764\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[0;32m    766\u001b[0m         prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    767\u001b[0m     )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1190\u001b[0m, in \u001b[0;36mBaseLLM.agenerate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m   1173\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1174\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1175\u001b[0m             callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1187\u001b[0m         ]\n\u001b[0;32m   1188\u001b[0m     )\n\u001b[0;32m   1189\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [r[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m run_managers]  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m-> 1190\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_helper(\n\u001b[0;32m   1191\u001b[0m         prompts,\n\u001b[0;32m   1192\u001b[0m         stop,\n\u001b[0;32m   1193\u001b[0m         run_managers,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1194\u001b[0m         \u001b[38;5;28mbool\u001b[39m(new_arg_supported),\n\u001b[0;32m   1195\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m     )\n\u001b[0;32m   1197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m   1198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1030\u001b[0m, in \u001b[0;36mBaseLLM._agenerate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1025\u001b[0m         \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1026\u001b[0m             run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m   1027\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers\n\u001b[0;32m   1028\u001b[0m         ]\n\u001b[0;32m   1029\u001b[0m     )\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1031\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m   1032\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1033\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1034\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(flattened_output)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1038\u001b[0m     ]\n\u001b[0;32m   1039\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:1014\u001b[0m, in \u001b[0;36mBaseLLM._agenerate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agenerate_helper\u001b[39m(\n\u001b[0;32m   1005\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1006\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1011\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1013\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1014\u001b[0m             \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(\n\u001b[0;32m   1015\u001b[0m                 prompts,\n\u001b[0;32m   1016\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m   1017\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1018\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1019\u001b[0m             )\n\u001b[0;32m   1020\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m   1021\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m   1022\u001b[0m         )\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1024\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[0;32m   1025\u001b[0m             \u001b[38;5;241m*\u001b[39m[\n\u001b[0;32m   1026\u001b[0m                 run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m   1027\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers\n\u001b[0;32m   1028\u001b[0m             ]\n\u001b[0;32m   1029\u001b[0m         )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_ollama\\llms.py:307\u001b[0m, in \u001b[0;36mOllamaLLM._agenerate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 307\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_astream_with_aggregation(\n\u001b[0;32m    308\u001b[0m         prompt,\n\u001b[0;32m    309\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    310\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    311\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    313\u001b[0m     )\n\u001b[0;32m    314\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_ollama\\llms.py:224\u001b[0m, in \u001b[0;36mOllamaLLM._astream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_astream_with_aggregation\u001b[39m(\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    217\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    223\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acreate_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    226\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[0;32m    227\u001b[0m                 text\u001b[38;5;241m=\u001b[39mstream_resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_resp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    228\u001b[0m                 generation_info\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    229\u001b[0m                     \u001b[38;5;28mdict\u001b[39m(stream_resp) \u001b[38;5;28;01mif\u001b[39;00m stream_resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    230\u001b[0m                 ),\n\u001b[0;32m    231\u001b[0m             )\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\langchain_ollama\\llms.py:200\u001b[0m, in \u001b[0;36mOllamaLLM._acreate_generate_stream\u001b[1;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acreate_generate_stream\u001b[39m(\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    196\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    197\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    198\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    199\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AsyncIterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_params(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    202\u001b[0m     ):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m part\n",
      "File \u001b[1;32md:\\anaconda3\\envs\\kmgraph\\Lib\\site-packages\\ollama\\_client.py:673\u001b[0m, in \u001b[0;36mAsyncClient._request.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    671\u001b[0m part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;241m:=\u001b[39m part\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 673\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(err)\n\u001b[0;32m    674\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n",
      "\u001b[1;31mResponseError\u001b[0m: POST predict: Post \"http://127.0.0.1:54730/completion\": read tcp 127.0.0.1:54734->127.0.0.1:54730: wsarecv: An existing connection was forcibly closed by the remote host."
     ]
    }
   ],
   "source": [
    "graph_documents = await llm_transformer.aconvert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(url=uri, username=user, password=password, enhanced_schema=True)\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cypher Query:\n",
    "```Cypher\n",
    "MATCH p=(m:Movie)-[r]-(n)\n",
    "RETURN p;\n",
    "```\n",
    "\n",
    "![llm_graph_transformer.jpeg](imgs/llm_graph_transformer.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH p=(n:Title {id: 'David Copperfield'})-[*1..2]-()\n",
      "RETURN p\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'CAST_IN', {'id': 'Florence La Badie'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'RELEASE_YEAR', {'id': '1911'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'GENRE', {'id': 'Drama'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'DIRECTED', {'id': 'Theodore Marston'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'ORIGIN_ETHNICITY', {'id': 'American'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'CAST_IN', {'id': 'Mignon Anderson'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'CAST_IN', {'id': 'William Russell'}]}, {'p': [{'id': 'David Copperfield'}, 'TITLE', {'id': 'David Copperfield'}, 'CAST_IN', {'id': 'Marie Eline'}]}]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'David Copperfield is a 1911 American drama film directed by Theodore Marston. The movie stars David Copperfield, Florence La Badie, Mignon Anderson, William Russell, and Marie Eline in various roles. It provides an overview of the life and adventures of David Copperfield through the eyes of his various companions and experiences.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "\n",
    "# llm_chat = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-1.5-pro\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     api_key=api_key\n",
    "# )\n",
    "\n",
    "CYPHER_GENERATION_TEMPLATE = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "Schema:\n",
    "{schema}\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "Identify the main node, and return all the relationships and nodes connected to it.\n",
    "If no properties are provided, assume the nodes have only a property id.\n",
    "Please don't filter on relationships or connected nodes.\n",
    "\n",
    "Format the query as follows:\n",
    "MATCH p=(n:NodeLabel)-[r]-(m)\n",
    "WHERE n.id = 'value1'\n",
    "RETURN p\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "CYPHER_GENERATION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], template=CYPHER_GENERATION_TEMPLATE\n",
    ")\n",
    "\n",
    "chain = GraphCypherQAChain.from_llm(\n",
    "    llm, \n",
    "    graph=graph, \n",
    "    verbose=True, \n",
    "    allow_dangerous_requests=True, \n",
    "    return_intermediate_steps=True,\n",
    "    cypher_prompt=CYPHER_GENERATION_PROMPT\n",
    ")\n",
    "\n",
    "chain.run(\"Give me an overview of the movie titled David Copperfield.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database resetted successfully!\n"
     ]
    }
   ],
   "source": [
    "conn.reset_database()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
